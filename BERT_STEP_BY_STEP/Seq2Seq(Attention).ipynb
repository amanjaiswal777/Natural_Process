{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/aman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000492\n",
      "Epoch: 0800 cost = 0.000155\n",
      "Epoch: 1200 cost = 0.000076\n",
      "Epoch: 1600 cost = 0.000044\n",
      "Epoch: 2000 cost = 0.000029\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
