{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stanford CoreNLP integrates many of Stanford’s NLP tools, including the part-of-speech (POS) tagger, the named entity recognizer (NER), the parser, the coreference resolution system, sentiment analysis, bootstrapped pattern learning, and the open information extraction tools.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Stanford CoreNLP integrates many of Stanford’s NLP tools, including the part-of-speech (POS) tagger, the named entity recognizer (NER), the parser, the coreference resolution system, sentiment analysis, bootstrapped pattern learning, and the open information extraction tools.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#StanfordNLP is a collection of pre-trained state-of -the-art models.\n",
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors = \"tokenize,mwt,lemma,pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"The prospects for Britain’s orderly withdrawal from the European Union on March 29 have receded further, even as MPs rallied to stop a no-deal scenario. An amendment to the draft bill on the termination of London’s membership of the bloc obliges Prime Minister Theresa May to renegotiate her withdrawal agreement with Brussels. A Tory backbencher’s proposal calls on the government to come up with alternatives to the Irish backstop, a central tenet of the deal Britain agreed with the rest of the EU.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Token index=1;words=[<Word index=1;text=The;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art>]>\n",
      "<Token index=2;words=[<Word index=2;text=prospects;lemma=prospect;upos=NOUN;xpos=NNS;feats=Number=Plur>]>\n",
      "<Token index=3;words=[<Word index=3;text=for;lemma=for;upos=ADP;xpos=IN;feats=_>]>\n",
      "<Token index=4;words=[<Word index=4;text=Britain;lemma=Britain;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=5;words=[<Word index=5;text=’s;lemma='s;upos=PART;xpos=POS;feats=_>]>\n",
      "<Token index=6;words=[<Word index=6;text=orderly;lemma=orderly;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
      "<Token index=7;words=[<Word index=7;text=withdrawal;lemma=withdrawal;upos=NOUN;xpos=NN;feats=Number=Sing>]>\n",
      "<Token index=8;words=[<Word index=8;text=from;lemma=from;upos=ADP;xpos=IN;feats=_>]>\n",
      "<Token index=9;words=[<Word index=9;text=the;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art>]>\n",
      "<Token index=10;words=[<Word index=10;text=European;lemma=european;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
      "<Token index=11;words=[<Word index=11;text=Union;lemma=union;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=12;words=[<Word index=12;text=on;lemma=on;upos=ADP;xpos=IN;feats=_>]>\n",
      "<Token index=13;words=[<Word index=13;text=March;lemma=March;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=14;words=[<Word index=14;text=29;lemma=29;upos=NUM;xpos=CD;feats=NumType=Card>]>\n",
      "<Token index=15;words=[<Word index=15;text=have;lemma=have;upos=AUX;xpos=VBP;feats=Mood=Ind|Tense=Pres|VerbForm=Fin>]>\n",
      "<Token index=16;words=[<Word index=16;text=receded;lemma=recede;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part>]>\n",
      "<Token index=17;words=[<Word index=17;text=further;lemma=further;upos=ADV;xpos=RB;feats=_>]>\n",
      "<Token index=18;words=[<Word index=18;text=,;lemma=,;upos=PUNCT;xpos=,;feats=_>]>\n",
      "<Token index=19;words=[<Word index=19;text=even;lemma=even;upos=ADV;xpos=RB;feats=_>]>\n",
      "<Token index=20;words=[<Word index=20;text=as;lemma=as;upos=SCONJ;xpos=IN;feats=_>]>\n",
      "<Token index=21;words=[<Word index=21;text=MPs;lemma=mps;upos=PROPN;xpos=NNPS;feats=Number=Plur>]>\n",
      "<Token index=22;words=[<Word index=22;text=rallied;lemma=rally;upos=VERB;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin>]>\n",
      "<Token index=23;words=[<Word index=23;text=to;lemma=to;upos=PART;xpos=TO;feats=_>]>\n",
      "<Token index=24;words=[<Word index=24;text=stop;lemma=stop;upos=VERB;xpos=VB;feats=VerbForm=Inf>]>\n",
      "<Token index=25;words=[<Word index=25;text=a;lemma=a;upos=DET;xpos=DT;feats=Definite=Ind|PronType=Art>]>\n",
      "<Token index=26;words=[<Word index=26;text=no-deal;lemma=no-deal;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
      "<Token index=27;words=[<Word index=27;text=scenario;lemma=scenario;upos=NOUN;xpos=NN;feats=Number=Sing>]>\n",
      "<Token index=28;words=[<Word index=28;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_>]>\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prospects</td>\n",
       "      <td>prospect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britain</td>\n",
       "      <td>Britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>’s</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>rest</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>EU</td>\n",
       "      <td>EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     lemma\n",
       "0         The       the\n",
       "1   prospects  prospect\n",
       "2         for       for\n",
       "3     Britain   Britain\n",
       "4          ’s        's\n",
       "..        ...       ...\n",
       "86       rest      rest\n",
       "87         of        of\n",
       "88        the       the\n",
       "89         EU        EU\n",
       "90          .         .\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#extract lemma\n",
    "def extract_lemma(doc):\n",
    "    parsed_text = {'word':[], 'lemma':[]}\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            #extract text and lemma\n",
    "            parsed_text['word'].append(wrd.text)\n",
    "            parsed_text['lemma'].append(wrd.lemma)\n",
    "    #return a dataframe\n",
    "    return pd.DataFrame(parsed_text)\n",
    "\n",
    "#call the function on doc\n",
    "extract_lemma(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prospects</td>\n",
       "      <td>NNS</td>\n",
       "      <td>noun plural 'desks'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>preposition/subordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britain</td>\n",
       "      <td>NNP</td>\n",
       "      <td>proper noun, singular 'Harrison'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>’s</td>\n",
       "      <td>POS</td>\n",
       "      <td>possessive ending parent's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>rest</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, singular 'desk'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>preposition/subordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>proper noun, singular 'Harrison'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  pos                                    exp\n",
       "0         The   DT                             determiner\n",
       "1   prospects  NNS                    noun plural 'desks'\n",
       "2         for   IN  preposition/subordinating conjunction\n",
       "3     Britain  NNP       proper noun, singular 'Harrison'\n",
       "4          ’s  POS             possessive ending parent's\n",
       "..        ...  ...                                    ...\n",
       "86       rest   NN                  noun, singular 'desk'\n",
       "87         of   IN  preposition/subordinating conjunction\n",
       "88        the   DT                             determiner\n",
       "89         EU  NNP       proper noun, singular 'Harrison'\n",
       "90          .    .                                     NA\n",
       "\n",
       "[91 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary that contains pos tags and their explanations\n",
    "pos_dict = {\n",
    "'CC': 'coordinating conjunction','CD': 'cardinal digit','DT': 'determiner',\n",
    "'EX': 'existential there (like: \\\"there is\\\" ... think of it like \\\"there exists\\\")',\n",
    "'FW': 'foreign word','IN':  'preposition/subordinating conjunction','JJ': 'adjective \\'big\\'',\n",
    "'JJR': 'adjective, comparative \\'bigger\\'','JJS': 'adjective, superlative \\'biggest\\'',\n",
    "'LS': 'list marker 1)','MD': 'modal could, will','NN': 'noun, singular \\'desk\\'',\n",
    "'NNS': 'noun plural \\'desks\\'','NNP': 'proper noun, singular \\'Harrison\\'',\n",
    "'NNPS': 'proper noun, plural \\'Americans\\'','PDT': 'predeterminer \\'all the kids\\'',\n",
    "'POS': 'possessive ending parent\\'s','PRP': 'personal pronoun I, he, she',\n",
    "'PRP$': 'possessive pronoun my, his, hers','RB': 'adverb very, silently,',\n",
    "'RBR': 'adverb, comparative better','RBS': 'adverb, superlative best',\n",
    "'RP': 'particle give up','TO': 'to go \\'to\\' the store.','UH': 'interjection errrrrrrrm',\n",
    "'VB': 'verb, base form take','VBD': 'verb, past tense took',\n",
    "'VBG': 'verb, gerund/present participle taking','VBN': 'verb, past participle taken',\n",
    "'VBP': 'verb, sing. present, non-3d take','VBZ': 'verb, 3rd person sing. present takes',\n",
    "'WDT': 'wh-determiner which','WP': 'wh-pronoun who, what','WP$': 'possessive wh-pronoun whose',\n",
    "'WRB': 'wh-abverb where, when','QF' : 'quantifier, bahut, thoda, kam (Hindi)','VM' : 'main verb',\n",
    "'PSP' : 'postposition, common in indian langs','DEM' : 'demonstrative, common in indian langs'\n",
    "}\n",
    "\n",
    "#extract parts of speech\n",
    "def extract_pos(doc):\n",
    "    parsed_text = {'word':[], 'pos':[], 'exp':[]}\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            if wrd.pos in pos_dict.keys():\n",
    "                pos_exp = pos_dict[wrd.pos]\n",
    "            else:\n",
    "                pos_exp = 'NA'\n",
    "            parsed_text['word'].append(wrd.text)\n",
    "            parsed_text['pos'].append(wrd.pos)\n",
    "            parsed_text['exp'].append(pos_exp)\n",
    "    #return a dataframe of pos and text\n",
    "    return pd.DataFrame(parsed_text)\n",
    "\n",
    "#extract pos\n",
    "extract_pos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = doc.sentences[1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/aman/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
